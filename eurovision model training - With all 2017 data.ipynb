{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Eurovision Ranking (LinReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from random import randint\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "    \"\"\"\n",
    "    Utility function to classify sentiment of passed tweet\n",
    "    using textblob's sentiment method\n",
    "    \"\"\"\n",
    "\n",
    "    # create TextBlob object of passed tweet text\n",
    "    analysis = TextBlob(clean_tweet(tweet['tweetText']))\n",
    "    \n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean tweet text by removing links, special characters\n",
    "    using simple regex statements.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = {}\n",
    "\n",
    "# set country hashtags - semifinal 1\n",
    "hashtags['2017_semi1'] = ['SWE', 'GEO', 'AUS', 'ALB', 'BEL', 'MNE', 'FIN', 'AZE', 'POR', 'GRE',\\\n",
    "                            'POL', 'MDA', 'ISL', 'CZE', 'CYP', 'ARM', 'SLO', 'LAT']\n",
    "\n",
    "# set country hashtags - semifinal 2\n",
    "hashtags['2017_semi2'] = ['AUT', 'BLR', 'DEN', 'EST', 'MKD', 'HUN', 'IRL', 'ISR', 'LTU', 'MLT', \\\n",
    "                            'NOR', 'ROM', 'SMR', 'SRB', 'SUI', 'NED', 'CRO', 'BUL']\n",
    "\n",
    "# set country hashtags - final\n",
    "hashtags['2017_final'] = ['ARM', 'AZE', 'ITA', 'MDA', 'POL', 'POR', 'UKR', 'AUS', 'BEL', 'CYP', 'FRA',\\\n",
    "                          'GER', 'GRE', 'ESP', 'GBR', 'SWE', 'BUL', 'BLR', 'CRO', 'HUN', 'DEN',\\\n",
    "                          'ISR', 'ROM', 'NOR', 'NED', 'AUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_final: 26\n",
      "2017_semi1: 18\n",
      "2017_semi2: 18\n"
     ]
    }
   ],
   "source": [
    "# read csv file with results\n",
    "results_list = {'2017_semi1':[], '2017_semi2':[], '2017_final':[]}\n",
    "with open('results.csv', 'r') as results_csv:\n",
    "    csv_reader = csv.reader(results_csv, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        if len(row) > 0:\n",
    "            if row[0] not in ('round'):\n",
    "                results_list[row[0]].append({\n",
    "                    'country':row[2],\n",
    "                    'rank':row[3],\n",
    "                    'televoting':row[4],\n",
    "                    'jury':row[5]\n",
    "                })\n",
    "\n",
    "# create dataframe\n",
    "results = pd.DataFrame()\n",
    "for round in results_list:\n",
    "    round_df = pd.DataFrame(results_list[round])\n",
    "    round_df['round'] = round\n",
    "    if len(results) == 0:\n",
    "        results = round_df\n",
    "    else:\n",
    "        results = results.append(round_df, ignore_index=True)\n",
    "    print('{}: {}'.format(round,len(results_list[round])))\n",
    "\n",
    "# convert to numeric values\n",
    "results['rank'] = pd.to_numeric(results['rank'], errors='coerce').fillna(0).astype(np.int64)\n",
    "results['televoting'] = pd.to_numeric(results['televoting'], errors='coerce').fillna(0).astype(np.int64)\n",
    "results['jury'] = pd.to_numeric(results['jury'], errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "# add total points\n",
    "results['total'] = results.apply(lambda r: int(r['jury']) + int(r['televoting']), axis=1)\n",
    "\n",
    "# add % of total points\n",
    "results['total_perc'] = results['total']/results['total'].sum()\n",
    "\n",
    "# sort columns\n",
    "results = results[['round', 'country', 'rank', 'jury', 'televoting', 'total', 'total_perc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose the Data table (features and labels) from different rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing round 2017_final\n",
      "  Reading sentiments\n",
      "  Counting tweets\n",
      "  Initializing dataframe of length 26 into global dataframe of length 0\n",
      "  Initialized global dataframe with length 26\n",
      "Processing round 2017_semi1\n",
      "  Reading sentiments\n",
      "  Counting tweets\n",
      "  Appending dataframe of length 18 into global dataframe of length 26\n",
      "  Appended global dataframe with length 44\n",
      "Processing round 2017_semi2\n",
      "  Reading sentiments\n",
      "  Counting tweets\n",
      "  Appending dataframe of length 18 into global dataframe of length 44\n",
      "  Appended global dataframe with length 62\n"
     ]
    }
   ],
   "source": [
    "all_rounds_data = pd.DataFrame()\n",
    "\n",
    "for round_string in ['2017_final', '2017_semi1', '2017_semi2']:\n",
    "    \n",
    "    print('Processing round', round_string)\n",
    "\n",
    "    #select db\n",
    "    if round_string == '2017_final':\n",
    "        sqlite_file = 'db_2017_friday_and_final.db'        \n",
    "    else:\n",
    "        sqlite_file = 'db_' + round_string + '.db'\n",
    "\n",
    "    # Connect to the database sqlite file\n",
    "    connection = sqlite3.connect(sqlite_file)\n",
    "    db = connection.cursor()\n",
    "\n",
    "    # read ALL tweets in english from db, evaluate sentiment, and count\n",
    "    print('  Reading sentiments')\n",
    "    round_sentiments = []\n",
    "    for country in hashtags[round_string]:\n",
    "\n",
    "        # get tweets from DB\n",
    "        country_tweets = pd.read_sql_query(\"SELECT * FROM TweetsRaw WHERE language='en' AND tweetText LIKE '%#{}%'\".format(country), connection)\n",
    "\n",
    "        # count number of sentiments\n",
    "        sentiments_count = Counter(country_tweets.apply(get_tweet_sentiment, axis=1))\n",
    "\n",
    "        # append country to list\n",
    "        round_sentiments.append({'country': country, \\\n",
    "                               'positive': sentiments_count['positive'],\\\n",
    "                               'neutral': sentiments_count['neutral'],\\\n",
    "                               'negative': sentiments_count['negative']\n",
    "                              })\n",
    "\n",
    "    # read all tweets (to just count)\n",
    "    print('  Counting tweets')\n",
    "    round_tweet_counts = []\n",
    "    for country in hashtags[round_string]:\n",
    "\n",
    "        # get tweet count from DB\n",
    "        db.execute(\"SELECT COUNT(*) AS count FROM TweetsRaw WHERE tweetText LIKE '%#{}%'\".format(country))\n",
    "        country_tweet_count = db.fetchone()[0]\n",
    "\n",
    "        # append country to list\n",
    "        round_tweet_counts.append({'country': country, \\\n",
    "                               'count': country_tweet_count\n",
    "                              })\n",
    "\n",
    "    # transform to pandas dataframe from sentiments list\n",
    "    round_data = pd.DataFrame(round_sentiments)\n",
    "    round_data['round'] = round_string\n",
    "\n",
    "    # add total tweet count\n",
    "    round_data['tweets'] = [tc['count'] for tc in round_tweet_counts]\n",
    "        \n",
    "    # merge with results\n",
    "    round_data = pd.merge(round_data, results, on=['country','round'], how='left')\n",
    "    \n",
    "    # re-order columns\n",
    "    round_data = round_data[['round','country',\\\n",
    "                                'tweets','negative','neutral','positive',\\\n",
    "                                'rank','jury','televoting','total', 'total_perc'\n",
    "                              ]]    \n",
    "\n",
    "    # append to dataframe with all rounds data\n",
    "    if len(all_rounds_data) == 0: \n",
    "        print('  Initializing dataframe of length',len(round_data),'into global dataframe of length',len(all_rounds_data))\n",
    "        all_rounds_data = round_data\n",
    "        print('  Initialized global dataframe with length',len(all_rounds_data))\n",
    "    else:\n",
    "        print('  Appending dataframe of length',len(round_data),'into global dataframe of length',len(all_rounds_data))\n",
    "        all_rounds_data = all_rounds_data.append(round_data, ignore_index=True)\n",
    "        print('  Appended global dataframe with length',len(all_rounds_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create normalized features\n",
    "\"\"\"\n",
    "results['negative_norm'] = (results['negative'] - results['negative'].mean() ) / results['negative'].std()\n",
    "results['neutral_norm'] = (results['neutral'] - results['neutral'].mean() ) / results['neutral'].std()\n",
    "results['positive_norm'] = (results['positive'] - results['positive'].mean() ) / results['positive'].std()\n",
    "results['tweets_norm'] = (results['tweets'] - results['tweets'].mean() ) / results['tweets'].std()\n",
    "results['negative_norm'] = results['negative'] / results['negative'].sum()\n",
    "results['neutral_norm'] = results['neutral'] / results['neutral'].sum()\n",
    "results['positive_norm'] = results['positive'] / results['positive'].sum()\n",
    "results['tweets_norm'] = results['tweets'] / results['tweets'].sum()\n",
    "\"\"\"\n",
    "\n",
    "# add percentages of features over the totals\n",
    "all_rounds_data['positive_perc'] = all_rounds_data['positive'] / all_rounds_data['positive'].sum()\n",
    "all_rounds_data['negative_perc'] = all_rounds_data['negative'] / all_rounds_data['negative'].sum()\n",
    "all_rounds_data['neutral_perc'] = all_rounds_data['neutral'] / all_rounds_data['neutral'].sum()\n",
    "all_rounds_data['tweets_perc'] = all_rounds_data['tweets'] / all_rounds_data['tweets'].sum()\n",
    "\n",
    "# create log features\n",
    "all_rounds_data['negative_log'] = np.log(1 + all_rounds_data['negative'])\n",
    "all_rounds_data['neutral_log'] = np.log(1 + all_rounds_data['neutral'])\n",
    "all_rounds_data['positive_log'] = np.log(1 + all_rounds_data['positive'])\n",
    "all_rounds_data['tweets_log'] = np.log(1 + all_rounds_data['tweets'])\n",
    "\n",
    "# create label 'isTopN'\n",
    "all_rounds_data['isTop5'] = all_rounds_data.apply(lambda r: 1 if r['rank']<=5 else 0, axis=1)\n",
    "all_rounds_data['isTop10'] = all_rounds_data.apply(lambda r: 1 if r['rank']<=10 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fabd276cb70>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eplore features\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "columns = [#'tweets', 'negative', 'neutral', 'positive',\\\n",
    "           'rank', 'isTop5', 'isTop10',\\\n",
    "           #'jury', 'televoting', 'total', 'total_perc',\\\n",
    "           'positive_perc', 'negative_perc', 'neutral_perc', 'tweets_perc']\n",
    "           #'negative_log', 'neutral_log','positive_log', 'tweets_log']\n",
    "data_to_plot = all_rounds_data[columns]\n",
    "#sns.pairplot(data_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 49\n",
      "X_test:  13\n",
      "y_train: 49\n",
      "y_test:  13\n",
      "\n",
      "Score train: 0.25625903568336417\n",
      "Score test:  0.04586627952493105\n",
      "\n",
      "   features     coefs\n",
      "0  intercep  0.000000\n",
      "1  negative  0.078345\n",
      "2   neutral -0.015520\n",
      "3  positive -0.023051\n",
      "4    tweets  0.004445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.007469</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.660751</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.261282</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.301531</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.110133</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.829666</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.707635</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.706985</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.476928</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.918433</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.422938</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.648362</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.605914</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted  real\n",
       "10  18.007469   7.0\n",
       "12  16.660751  17.0\n",
       "9   12.261282  14.0\n",
       "1   11.301531  19.0\n",
       "5   11.110133  23.0\n",
       "6   10.829666   5.0\n",
       "2   10.707635  12.0\n",
       "7   10.706985  12.0\n",
       "0   10.476928   1.0\n",
       "11   8.918433   9.0\n",
       "4    4.422938  11.0\n",
       "3    2.648362   4.0\n",
       "8    2.605914   3.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the features to analyze in the model\n",
    "features = ['negative', 'neutral', 'positive', 'tweets']\n",
    "#features = ['negative_log', 'neutral_log', 'positive_log', 'tweets_log']\n",
    "#features = ['negative_perc', 'neutral_perc', 'positive_perc', 'tweets_perc']\n",
    "features_string = ' + '.join(features)\n",
    "\n",
    "# create input matrix and outut array\n",
    "y, X = dmatrices('rank ~ {}'.format(features_string), all_rounds_data, return_type = 'dataframe')\n",
    "\n",
    "# sklearn split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=randint(0,1000))\n",
    "print('X_train: {}\\nX_test:  {}\\ny_train: {}\\ny_test:  {}\\n'.format(len(X_train),len(X_test),len(y_train),len(y_test)))\n",
    "\n",
    "# Linear Regression model with sklearn\n",
    "model = LinearRegression(fit_intercept = True, normalize = False, copy_X=True)\n",
    "regressor = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# print results\n",
    "print(\"Score train: {}\".format(regressor.score(X_train, y_train)))\n",
    "print(\"Score test:  {}\\n\".format(regressor.score(X_test, y_test)))\n",
    "\n",
    "# print feature relationship\n",
    "features_tmp = np.insert(features,0,'intercept')\n",
    "print(pd.DataFrame(list(zip(features_tmp, model.coef_.ravel())), columns=['features','coefs']))\n",
    "\n",
    "# predict test\n",
    "pd.DataFrame(list(zip(model.predict(X_test), y_test.values.ravel())), columns=['predicted','real']).sort_values('predicted', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with isTopN as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 43\n",
      "X_test:  19\n",
      "y_train: 43 23%\n",
      "y_test:  19 26%\n",
      "\n",
      "Classification performance metrics\n",
      " Accuracy: 0.631578947368421\n",
      " F1 Score: 0.22222222222222224\n",
      " ROC AUC:  0.4928571428571428\n",
      "\n",
      "       features     coefs\n",
      "0     intercept -0.883645\n",
      "1  negative_log -2.865041\n",
      "2   neutral_log -0.523624\n",
      "3  positive_log  3.009323\n",
      "4    tweets_log  1.089205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>isTop5</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>tweets</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017_final</td>\n",
       "      <td>MDA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>438</td>\n",
       "      <td>875</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.705261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017_final</td>\n",
       "      <td>POR</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>786</td>\n",
       "      <td>833</td>\n",
       "      <td>3377</td>\n",
       "      <td>1.807106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017_final</td>\n",
       "      <td>BUL</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>313</td>\n",
       "      <td>488</td>\n",
       "      <td>1364</td>\n",
       "      <td>0.518100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017_final</td>\n",
       "      <td>NED</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>922</td>\n",
       "      <td>563</td>\n",
       "      <td>2341</td>\n",
       "      <td>0.508773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017_final</td>\n",
       "      <td>FRA</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>210</td>\n",
       "      <td>179</td>\n",
       "      <td>1179</td>\n",
       "      <td>0.287857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         round country  rank  isTop5  negative  neutral  positive  tweets  \\\n",
       "3   2017_final     MDA     3       1        95      438       875    2024   \n",
       "5   2017_final     POR     1       1       138      786       833    3377   \n",
       "16  2017_final     BUL     2       1       106      313       488    1364   \n",
       "24  2017_final     NED    11       0       124      922       563    2341   \n",
       "10  2017_final     FRA    12       0        41      210       179    1179   \n",
       "\n",
       "    predicted_score  \n",
       "3          2.705261  \n",
       "5          1.807106  \n",
       "16         0.518100  \n",
       "24         0.508773  \n",
       "10         0.287857  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isTopN = 'isTop5'\n",
    "\n",
    "# set the features to analyze in the model\n",
    "#features = ['negative', 'neutral', 'positive', 'tweets']\n",
    "features = ['negative_log', 'neutral_log', 'positive_log', 'tweets_log']\n",
    "#features = ['negative_perc', 'neutral_perc', 'positive_perc', 'tweets_perc']\n",
    "features_string = ' + '.join(features)\n",
    "\n",
    "# create input matrix and outut array\n",
    "y, X = dmatrices('{} ~ {}'.format(isTopN, features_string), all_rounds_data, return_type = 'dataframe')\n",
    "\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "X_norm = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_norm[0] = 1 # set intercept back to 1 (scaler sets it to 0 because of 0 variance)\n",
    "\n",
    "# sklearn split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=randint(0,1000))\n",
    "print('X_train: {}\\nX_test:  {}\\ny_train: {} {}%\\ny_test:  {} {}%'.format(\n",
    "    len(X_train),\n",
    "    len(X_test),\n",
    "    len(y_train), int(100*y_train.sum()/len(y_train)),\n",
    "    len(y_test), int(100*y_test.sum()/len(y_test))\n",
    "))\n",
    "\n",
    "# Linear Regression model with sklearn\n",
    "regularization = 0.1\n",
    "model = LogisticRegression(fit_intercept = True, C = 1/regularization)\n",
    "regressor = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# predict test\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# print scores\n",
    "print('\\nClassification performance metrics')\n",
    "print(' Accuracy: {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print(' F1 Score: {}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(' ROC AUC:  {}\\n'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "\n",
    "# print feature relationship\n",
    "features_tmp = np.insert(features,0,'intercept')\n",
    "print(pd.DataFrame(list(zip(features_tmp, model.coef_.ravel())), columns=['features','coefs']))\n",
    "\n",
    "# compute the new predicted score using the feature weights modeled in Logistic Regression\n",
    "all_rounds_data['predicted_score'] = np.dot(X_norm.values, model.coef_.T)\n",
    "\n",
    "# compare predicted as topN\n",
    "all_rounds_data[all_rounds_data['round']=='2017_final'][['round','country','rank',isTopN,'negative', 'neutral', 'positive', 'tweets','predicted_score']].sort_values(by=['predicted_score'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist features, scaler and model to binary files\n",
    "import pickle\n",
    "with open(\"features.bin\", \"wb\") as f:\n",
    "    pickle.dump(features, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"scaler.bin\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"regressor.bin\", \"wb\") as f:\n",
    "    pickle.dump(regressor, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
