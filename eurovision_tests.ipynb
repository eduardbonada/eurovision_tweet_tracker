{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Eurovision Finalists results based on tweets\n",
    "\n",
    "Script that reads tweets from a database and processes the information to predict the results of the Eurovision Song Contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "    \"\"\"\n",
    "    Utility function to classify sentiment of passed tweet\n",
    "    using textblob's sentiment method\n",
    "    \"\"\"\n",
    "\n",
    "    # create TextBlob object of passed tweet text\n",
    "    analysis = TextBlob(clean_tweet(tweet['tweetText']))\n",
    "    \n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean tweet text by removing links, special characters\n",
    "    using simple regex statements.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup sqlite\n",
    "sqlite_file = 'eurovision_semis.db'\n",
    "\n",
    "# Connect to the database sqlite file\n",
    "connection = sqlite3.connect(sqlite_file)\n",
    "db = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# set country hashtags - semifinal 1\n",
    "all_hashtags = ['SWE', 'GEO', 'AUS', 'ALB', 'BEL', 'MNE', 'FIN', 'AZE', 'POR',\\\n",
    "                'POL', 'MDA', 'ISL', 'CZE', 'CYP', 'ARM', 'SLO', 'LAT', 'GRE',\\\n",
    "                'AUT', 'BLR', 'DEN', 'EST', 'MKD', 'HUN', 'IRL', 'ISR', 'LTU',\\\n",
    "                'NOR', 'ROM', 'SMR', 'SRB', 'SUI', 'NED', 'CRO', 'BUL', 'MLT',\\\n",
    "                'ITA', 'FRA', 'ESP', 'GBR', 'UKR', 'GER']\n",
    "\n",
    "hashtags_semi1 = ['SWE', 'GEO', 'AUS', 'ALB', 'BEL', 'MNE', 'FIN', 'AZE', 'POR', 'GRE',\\\n",
    "                    'POL', 'MDA', 'ISL', 'CZE', 'CYP', 'ARM', 'SLO', 'LAT']\n",
    "\n",
    "# set country hashtags - semifinal 2\n",
    "hashtags_semi2 = ['AUT', 'BLR', 'DEN', 'EST', 'MKD', 'HUN', 'IRL', 'ISR', 'LTU', 'MLT', \\\n",
    "                    'NOR', 'ROM', 'SMR', 'SRB', 'SUI', 'NED', 'CRO', 'BUL']\n",
    "\n",
    "# set country hashtags - final\n",
    "hashtags_final = ['ARM', 'AZE', 'ITA', 'MDA', 'POL', 'POR', 'UKR', 'AUS', 'BEL', 'CYP', 'FRA',\\\n",
    "                  'GER', 'GRE', 'ESP', 'GBR', 'SWE', 'BUL', 'BLR', 'CRO', 'HUN', 'DEN',\\\n",
    "                  'ISR', 'ROM', 'NOR', 'NED', 'AUT']\n",
    "\n",
    "hashtags = hashtags_semi1 + hashtags_semi2\n",
    "print(len(hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count tweets and analyze sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read ALL tweets in english from db, evaluate sentiment, and count - SEMI 1\n",
    "all_sentiments = []\n",
    "for country in hashtags:\n",
    "\n",
    "    # get tweets from DB\n",
    "    country_tweets = pd.read_sql_query(\"SELECT * FROM TweetsRaw WHERE language='en' AND tweetText LIKE '%#{}%'\".format(country), connection)\n",
    "\n",
    "    # count number of sentiments\n",
    "    sentiments_count = Counter(country_tweets.apply(get_tweet_sentiment, axis=1))\n",
    "    \n",
    "    # append country to list\n",
    "    all_sentiments.append({'country': country, \\\n",
    "                           'positive': sentiments_count['positive'],\\\n",
    "                           'neutral': sentiments_count['neutral'],\\\n",
    "                           'negative': sentiments_count['negative']\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read all tweets (to just count)\n",
    "all_tweet_counts = []\n",
    "for country in hashtags:\n",
    "\n",
    "    # get tweet count from DB\n",
    "    db.execute(\"SELECT COUNT(*) AS count FROM TweetsRaw WHERE tweetText LIKE '%#{}%'\".format(country))\n",
    "    country_tweet_count = db.fetchone()[0]\n",
    "    \n",
    "    # append country to list\n",
    "    all_tweet_counts.append({'country': country, \\\n",
    "                           'count': country_tweet_count\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform to pandas dataframe from sentiments list\n",
    "results = pd.DataFrame(all_sentiments)\n",
    "results = results.set_index(['country'])\n",
    "\n",
    "# add total tweet count\n",
    "results['tweets'] = [tc['count'] for tc in all_tweet_counts]\n",
    "\n",
    "# add percentages of features over the totals\n",
    "results['positive_perc'] = results['positive'] / results['positive'].sum()\n",
    "results['negative_perc'] = results['negative'] / results['negative'].sum()\n",
    "results['neutral_perc'] = results['neutral'] / results['neutral'].sum()\n",
    "results['tweets_perc'] = results['tweets'] / results['tweets'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add finalist 'column'\n",
    "results['finalist'] = 0\n",
    "\n",
    "results.loc['MDA','finalist'] = 1\n",
    "results.loc['AZE','finalist'] = 1\n",
    "results.loc['GRE','finalist'] = 1\n",
    "results.loc['SWE','finalist'] = 1\n",
    "results.loc['POR','finalist'] = 1\n",
    "results.loc['POL','finalist'] = 1\n",
    "results.loc['ARM','finalist'] = 1\n",
    "results.loc['AUS','finalist'] = 1\n",
    "results.loc['CYP','finalist'] = 1\n",
    "results.loc['BEL','finalist'] = 1\n",
    "results.loc['BUL','finalist'] = 1\n",
    "results.loc['BLR','finalist'] = 1\n",
    "results.loc['CRO','finalist'] = 1\n",
    "results.loc['HUN','finalist'] = 1\n",
    "results.loc['DEN','finalist'] = 1\n",
    "results.loc['ISR','finalist'] = 1\n",
    "results.loc['ROM','finalist'] = 1\n",
    "results.loc['NOR','finalist'] = 1\n",
    "results.loc['NED','finalist'] = 1\n",
    "results.loc['AUT','finalist'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create normalized features\n",
    "results['negative_norm'] = (results['negative'] - results['negative'].mean() ) / results['negative'].std()\n",
    "results['neutral_norm'] = (results['neutral'] - results['neutral'].mean() ) / results['neutral'].std()\n",
    "results['positive_norm'] = (results['positive'] - results['positive'].mean() ) / results['positive'].std()\n",
    "results['tweets_norm'] = (results['tweets'] - results['tweets'].mean() ) / results['tweets'].std()\n",
    "#results['negative_norm'] = results['negative'] / results['negative'].sum()\n",
    "#results['neutral_norm'] = results['neutral'] / results['neutral'].sum()\n",
    "#results['positive_norm'] = results['positive'] / results['positive'].sum()\n",
    "#results['tweets_norm'] = results['tweets'] / results['tweets'].sum()\n",
    "\n",
    "# create log features\n",
    "results['negative_log'] = np.log(1 + results['negative_perc'])\n",
    "results['neutral_log'] = np.log(1 + results['neutral_perc'])\n",
    "results['positive_log'] = np.log(1 + results['positive_perc'])\n",
    "results['tweets_log'] = np.log(1 + results['tweets_perc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the features to analyze in the model\n",
    "features = ['negative_log', 'neutral_log', 'positive_log', 'tweets_log']\n",
    "#features = ['negative_norm', 'neutral_norm', 'positive_norm', 'tweets_norm']\n",
    "#features = ['negative_log', 'neutral_log', 'positive_log', 'tweets_log', \\\n",
    "#            'negative_norm', 'neutral_norm', 'positive_norm', 'tweets_norm']\n",
    "features_string = ' + '.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create input matrix and outut array\n",
    "y, X = dmatrices('finalist ~ {}'.format(features_string), results, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.05035294 -24.682529     1.95287805  19.18785507  12.02347988]] 0.875\n",
      "[[  0.10516202 -21.41942666   3.46204239   6.83032191   9.6334635 ]] 0.875\n",
      "[[ -0.07559544 -17.58394658   2.35064451  16.89248464  12.50045079]] 0.875\n",
      "[[  1.47652550e-02  -1.72236421e+01  -1.64265073e+00   1.26120143e+01\n",
      "    1.26697413e+01]] 0.875\n",
      "[[  3.60854143e-03  -1.64930061e+01  -8.34671418e+00   2.17190026e+01\n",
      "    9.66318404e+00]] 0.875\n",
      "[[ -0.07420078 -22.76248969   0.76440756  16.07724795  10.94839982]] 0.875\n",
      "[[  1.84399964e-02  -2.13820138e+01   5.12443718e+00   8.85120417e+00\n",
      "    1.29684041e+01]] 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.linear_model as lm\n",
    "\n",
    "best_score = 0\n",
    "for it in range(0,100):\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=randint(0,1000))\n",
    "\n",
    "    # Logistic Regression model with sklearn\n",
    "    regularization = 0.001\n",
    "    model = lm.LogisticRegression(fit_intercept = False, C = 1/regularization)\n",
    "    classifier = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # print results if best score so far\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    if score >= best_score:\n",
    "        print(classifier.coef_, classifier.score(X_test, y_test))\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.5\n",
      "0.625\n",
      "0.625\n",
      "0.625\n",
      "0.75\n",
      "0.75\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "best_score = 0\n",
    "for it in range(0,100):\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=randint(0,1000))\n",
    "\n",
    "    # Create a Gaussian Classifier and train the model\n",
    "    model = GaussianNB()\n",
    "    classifier = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # print results if best score so far\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    if score >= best_score:\n",
    "        print(classifier.score(X_test, y_test))\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.75\n",
      "0.875\n",
      "0.875\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "best_score = 0\n",
    "for it in range(0,100):\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=randint(0,1000))\n",
    "\n",
    "    # Create a Gaussian Classifier and train the model\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    classifier = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # print results if best score so far\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    if score >= best_score:\n",
    "        print(classifier.score(X_test, y_test))\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Timelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tweets = pd.read_sql_query(\"SELECT *                              FROM TweetsRaw\", connection)\n",
    "\n",
    "band_tweets['createdAt'] = pd.to_datetime(band_tweets['createdAt'], format ='%a %b %d %H:%M:%S +0000 %Y')\n",
    "band_tweets.index = band_tweets['createdAt']\n",
    "band_tweets.resample('H').count()['bandId'].plot(kind='area')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
